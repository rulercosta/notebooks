\chapter{Properties of Matrix Operations}

\section{Properties of Matrix Operations}

The operations are as follows:

\subsection{Addition}

If \(\mathbf{A}\) and \(\mathbf{B}\) are matrices of the same size \(m \times n\), then \(\mathbf{A} + \mathbf{B}\), their sum, is a matrix of size \(m \times n\).

\subsection{Multiplication by Scalars}

If \(\mathbf{A}\) is a matrix of size \(m \times n\) and \(\alpha\) is a scalar, then \(\alpha \mathbf{A}\) is a matrix of size \(m \times n\).

\subsection{Matrix Multiplication}

If \(\mathbf{A}\) is a matrix of size \(m \times n\) and \(\mathbf{B}\) is a matrix of size \(n \times p\), then the product \(\mathbf{AB}\) is a matrix of size \(m \times p\).

\subsection{Vectors}

A vector of length \(n\) can be treated as a matrix of size \(n \times 1\), and the operations of vector addition, multiplication by scalars, and multiplying a matrix by a vector agree with the corresponding matrix operations.

\subsection{Transpose}

If \(\mathbf{A}\) is a matrix of size \(m \times n\), then its transpose \(\mathbf{A}^{\mathsf{T}}\) is a matrix of size \(n \times m\).

\subsection{Identity Matrix}

An identity matrix is a matrix that does not change any vector when we multiply that vector by that matrix. We denote the identity matrix that preserves \(n\)-dimensional vectors as \(\mathbf{I}_{n}\). Formally, \(\mathbf{I}_{n} \in \mathbb{R}^{n \times n}\), and
\begin{align}
\forall \ \mathbf{x} \in \mathbb{R}^{n}, \ \mathbf{I}_{n} \mathbf{x} = \mathbf{x}.
\end{align}
\(\mathbf{I}_{n}\) is the \(n \times n\) identity matrix; its principal diagonal elements are equal to \(1\) and its off-diagonal elements are equal to \(0\).

\subsection{Zero Matrix}

It is denoted by \(0\), the matrix of all zeroes (of relevant size).

\subsection{Inverse}

If \(\mathbf{A}\) is a square matrix, then its inverse \(\mathbf{A}^{-1}\) is a matrix of the same size. The matrices that have nonzero determinant have inverses and are called invertible.

For square matrices,
\begin{align}
\mathbf{A} \mathbf{A}^{-1} = \mathbf{A}^{-1} \mathbf{A} = \mathbf{I}_{n}
\end{align}

In many cases, we can treat addition and multiplication of matrices as addition and multiplication of numbers. However, there are some differences between operations with matrices and operations with numbers:
\begin{itemize}
    \item Properties such as associative, distributive, and commutative are followed in scalar multiplication and matrix addition.
    \item Matrix multiplication does not commute.
    \item In general, \(\mathbf{AB} \neq \mathbf{BA}\), even if \(\mathbf{A}\) and \(\mathbf{B}\) are both square matrices. If \(\mathbf{AB} = \mathbf{BA}\), then we say that \(\mathbf{A}\) and \(\mathbf{B}\) commute.
    \item For a general matrix \(\mathbf{A}\), we cannot say that \(\mathbf{AB} = \mathbf{AC}\) yields \(\mathbf{B} = \mathbf{C}\). However, if we know that \(\mathbf{A}\) is invertible, then we can multiply both sides of the equation \(\mathbf{AB} = \mathbf{AC}\) to the left by \(\mathbf{A}^{-1}\) and get \(\mathbf{B} = \mathbf{C}\).
    \item The equation \(\mathbf{AB} = 0\) does not necessarily yield \(\mathbf{A} = 0\) or \(\mathbf{B} = 0\). For example, take:
    \begin{align}
    \mathbf{A} = \begin{bmatrix} 1 & 0 \\ 0 & 0 \end{bmatrix}, \quad
    \mathbf{B} = \begin{bmatrix} 0 & 0 \\ 0 & 1 \end{bmatrix}.
    \end{align}
\end{itemize}
\para

\section{A Note on the Methods of Solving a System of Linear Equations}

Apart from the usual (direct) methods of solving a system of linear equations, which includes, Elimination Method, Substitution Method, and Cross Multiplication Method, there are various other methods of solving a system of linear equations:
\begin{itemize}
    \item \textbf{Matrix Method}:
    \begin{itemize}
        \item Cramer's Rule
        \item Gaussian Elimination
        \item Gauss-Jordan Method
        \item Triangularization Method
        \item Cholesky Method
        \item Partition Method
    \end{itemize}
    \item \textbf{Iterative Methods}:
    \begin{itemize}
        \item Jacobi Iterative Method
        \item Gauss-Seidel Iterative Method
        \item SOR Method
    \end{itemize}
\end{itemize}
\para

It might seem overwhelming at first but as other properties of and special types of matrices are introduced, these methods will become easier to grasp. However, it must be noted that when it comes to solving a system of linear equations, in our case, we require a fast and efficient algorithm, so it would be fine not having some if not most of these methods on your fingertips.
\para

\textbf{Note:} \textit{This section will be expanded in the future.}